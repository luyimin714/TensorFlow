{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow中的基本RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
    "X1 = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=(n_inputs, n_neurons), dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=(n_neurons, n_neurons), dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros(shape=(1, n_neurons), dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8960613  -0.2378181  -0.13065062 -0.7704926   0.83936375]\n",
      " [ 0.9996792  -0.69378126 -0.9424555   0.9999672   0.02875524]\n",
      " [ 0.99999905 -0.8991875  -0.99771976  1.         -0.82152474]\n",
      " [ 0.99748886  0.99777275 -0.9999996   1.         -1.        ]]\n",
      "[[ 0.99999654 -0.98873156 -0.99986076  1.         -0.99999905]\n",
      " [ 0.8602821  -0.6243707   0.80740273 -0.9987659  -0.99889207]\n",
      " [ 0.99999183 -0.94118714 -0.99101806  1.         -0.99998206]\n",
      " [ 0.9997068  -0.9877578  -0.34135965  0.9993494  -0.99935824]]\n"
     ]
    }
   ],
   "source": [
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]])\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "    \n",
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过时间静态展开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30741334 -0.32884315 -0.6542847  -0.9385059   0.52089024]\n",
      " [ 0.99122757 -0.9542542  -0.7518079  -0.9995208   0.9820235 ]\n",
      " [ 0.9999268  -0.99783254 -0.8247353  -0.9999963   0.99947774]\n",
      " [ 0.996771   -0.68750614  0.8419969   0.9303911   0.8120684 ]]\n",
      "[[ 0.99998885 -0.9997605  -0.06679298 -0.9999804   0.99982214]\n",
      " [-0.6524944  -0.51520866 -0.37968954 -0.59225935 -0.08968385]\n",
      " [ 0.998624   -0.997152   -0.03308626 -0.9991565   0.9932902 ]\n",
      " [ 0.99681675 -0.9598194   0.39660636 -0.8307605   0.7967197 ]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
    "X1 = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1], dtype=tf.float32)\n",
    "\n",
    "Y0, Y1 = output_seqs\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]])\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "    \n",
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2, 3)\n",
      "[[[-0.45652324 -0.68064123  0.40938237  0.63104504 -0.45732826]\n",
      "  [-0.94288003 -0.9998869   0.94055814  0.9999985  -0.9999997 ]]\n",
      "\n",
      " [[-0.8001535  -0.9921827   0.7817797   0.9971031  -0.9964609 ]\n",
      "  [-0.637116    0.11300932  0.5798437   0.43105593 -0.63716984]]\n",
      "\n",
      " [[-0.93605185 -0.9998379   0.9308867   0.9999815  -0.99998295]\n",
      "  [-0.9165386  -0.9945604   0.89605415  0.99987197 -0.9999751 ]]\n",
      "\n",
      " [[ 0.9927369  -0.9981933  -0.55543643  0.9989031  -0.9953323 ]\n",
      "  [-0.02746334 -0.73191994  0.7827872   0.9525682  -0.97817713]]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_steps, n_inputs))\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1, 0, 2]))\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs, dtype=tf.float32)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "X_batch = np.array([\n",
    "    [[0, 1, 2], [9, 8, 7]],\n",
    "    [[3, 4, 5], [0, 0, 0]],\n",
    "    [[6, 7, 8], [6, 5, 4]],\n",
    "    [[9, 0, 1], [3, 2, 1]],\n",
    "])\n",
    "print(X_batch.shape)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})\n",
    "    \n",
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过时间动态展开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.85115266  0.87358344  0.5802911   0.8954789  -0.0557505 ]\n",
      "  [-0.9999959   0.9999958   0.9981815   1.          0.37679598]]\n",
      "\n",
      " [[-0.9983293   0.9992038   0.98071456  0.999985    0.2519265 ]\n",
      "  [-0.70818055 -0.07723375 -0.8522789   0.5845348  -0.7878095 ]]\n",
      "\n",
      " [[-0.9999827   0.99999535  0.9992863   1.          0.5159071 ]\n",
      "  [-0.9993956   0.9984095   0.83422637  0.9999999  -0.47325212]]\n",
      "\n",
      " [[ 0.87888587  0.07356028  0.97216916  0.9998546  -0.7351168 ]\n",
      "  [-0.91345143  0.36009577  0.7624866   0.99817705  0.80142   ]]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_steps, n_inputs))\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "X_batch = np.array([\n",
    "    [[0, 1, 2], [9, 8, 7]],\n",
    "    [[3, 4, 5], [0, 0, 0]],\n",
    "    [[6, 7, 8], [6, 5, 4]],\n",
    "    [[9, 0, 1], [3, 2, 1]],\n",
    "])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})\n",
    "    \n",
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输入序列长度可变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.89885193  0.8505537   0.56778944 -0.8374146  -0.2971686 ]\n",
      "  [ 0.3383331   0.99999976  0.9999229  -0.81598383 -0.9884344 ]]\n",
      "\n",
      " [[ 0.9687243   0.9997934   0.9865295  -0.97417724 -0.7423587 ]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.9905691   0.99999976  0.9996664  -0.99614036 -0.92241997]\n",
      "  [ 0.03740451  0.9997974   0.9984369   0.17223889 -0.9581747 ]]\n",
      "\n",
      " [[-0.99994785  0.9370876   0.9552368   0.9998339  -0.9967721 ]\n",
      "  [ 0.06362314  0.9876109   0.9854438   0.29195604  0.7661818 ]]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_steps, n_inputs))\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "\n",
    "seq_length = tf.placeholder(tf.int32, shape=(None))\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                    sequence_length=seq_length)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "X_batch = np.array([\n",
    "    [[0, 1, 2], [9, 8, 7]],\n",
    "    [[3, 4, 5], [0, 0, 0]],\n",
    "    [[6, 7, 8], [6, 5, 4]],\n",
    "    [[9, 0, 1], [3, 2, 1]],\n",
    "])\n",
    "seq_length_batch = np.array([2, 1, 2, 2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch, seq_length: seq_length_batch})\n",
    "    \n",
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3383331   0.99999976  0.9999229  -0.81598383 -0.9884344 ]\n",
      " [ 0.9687243   0.9997934   0.9865295  -0.97417724 -0.7423587 ]\n",
      " [ 0.03740451  0.9997974   0.9984369   0.17223889 -0.9581747 ]\n",
      " [ 0.06362314  0.9876109   0.9854438   0.29195604  0.7661818 ]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_steps, n_inputs))\n",
    "y = tf.placeholder(tf.int32, shape=(None))\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "print(X_train.shape)\n",
    "# X_train = X_train.reshape((-1, n_steps, n_inputs))\n",
    "# X_valid = X_valid.reshape((-1, n_steps, n_inputs))\n",
    "# X_test = X_test.reshape((-1, n_steps, n_inputs))\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Training acc: 0.514491 Validation acc: 0.515\n",
      "1 Training acc: 0.534909 Validation acc: 0.5348\n",
      "2 Training acc: 0.534782 Validation acc: 0.532\n",
      "3 Training acc: 0.544873 Validation acc: 0.5388\n",
      "4 Training acc: 0.549491 Validation acc: 0.5464\n",
      "5 Training acc: 0.553927 Validation acc: 0.5448\n",
      "6 Training acc: 0.557455 Validation acc: 0.555\n",
      "7 Training acc: 0.558927 Validation acc: 0.5516\n",
      "8 Training acc: 0.560018 Validation acc: 0.5524\n",
      "9 Training acc: 0.567691 Validation acc: 0.5642\n",
      "10 Training acc: 0.5698 Validation acc: 0.5726\n",
      "11 Training acc: 0.572036 Validation acc: 0.5598\n",
      "12 Training acc: 0.564964 Validation acc: 0.5606\n",
      "13 Training acc: 0.572018 Validation acc: 0.5674\n",
      "14 Training acc: 0.567873 Validation acc: 0.5656\n",
      "15 Training acc: 0.572945 Validation acc: 0.5626\n",
      "16 Training acc: 0.573382 Validation acc: 0.5696\n",
      "17 Training acc: 0.584055 Validation acc: 0.5772\n",
      "18 Training acc: 0.579618 Validation acc: 0.571\n",
      "19 Training acc: 0.574255 Validation acc: 0.567\n",
      "20 Training acc: 0.580291 Validation acc: 0.5694\n",
      "21 Training acc: 0.582582 Validation acc: 0.5728\n",
      "22 Training acc: 0.585018 Validation acc: 0.5782\n",
      "23 Training acc: 0.593891 Validation acc: 0.594\n",
      "24 Training acc: 0.577091 Validation acc: 0.5754\n",
      "25 Training acc: 0.589491 Validation acc: 0.573\n",
      "26 Training acc: 0.585745 Validation acc: 0.5668\n",
      "27 Training acc: 0.587382 Validation acc: 0.5878\n",
      "28 Training acc: 0.5936 Validation acc: 0.5898\n",
      "29 Training acc: 0.587 Validation acc: 0.5806\n",
      "30 Training acc: 0.597382 Validation acc: 0.5936\n",
      "31 Training acc: 0.587255 Validation acc: 0.576\n",
      "32 Training acc: 0.578691 Validation acc: 0.5724\n",
      "33 Training acc: 0.589164 Validation acc: 0.5806\n",
      "34 Training acc: 0.592655 Validation acc: 0.5842\n",
      "35 Training acc: 0.594455 Validation acc: 0.579\n",
      "36 Training acc: 0.599945 Validation acc: 0.5882\n",
      "37 Training acc: 0.6142 Validation acc: 0.607\n",
      "38 Training acc: 0.5808 Validation acc: 0.5724\n",
      "39 Training acc: 0.587745 Validation acc: 0.5778\n",
      "40 Training acc: 0.595836 Validation acc: 0.587\n",
      "41 Training acc: 0.605691 Validation acc: 0.6016\n",
      "42 Training acc: 0.607582 Validation acc: 0.5962\n",
      "43 Training acc: 0.608182 Validation acc: 0.5946\n",
      "44 Training acc: 0.616145 Validation acc: 0.6086\n",
      "45 Training acc: 0.605545 Validation acc: 0.5954\n",
      "46 Training acc: 0.607873 Validation acc: 0.6052\n",
      "47 Training acc: 0.604291 Validation acc: 0.5992\n",
      "48 Training acc: 0.600364 Validation acc: 0.5922\n",
      "49 Training acc: 0.607873 Validation acc: 0.5962\n",
      "50 Training acc: 0.600091 Validation acc: 0.5852\n",
      "51 Training acc: 0.603891 Validation acc: 0.5902\n",
      "52 Training acc: 0.597109 Validation acc: 0.5904\n",
      "53 Training acc: 0.609618 Validation acc: 0.601\n",
      "54 Training acc: 0.611055 Validation acc: 0.605\n",
      "55 Training acc: 0.6108 Validation acc: 0.6062\n",
      "56 Training acc: 0.604545 Validation acc: 0.5974\n",
      "57 Training acc: 0.601345 Validation acc: 0.5976\n",
      "58 Training acc: 0.614927 Validation acc: 0.6066\n",
      "59 Training acc: 0.6088 Validation acc: 0.5998\n",
      "60 Training acc: 0.6068 Validation acc: 0.5986\n",
      "61 Training acc: 0.601382 Validation acc: 0.5964\n",
      "62 Training acc: 0.619545 Validation acc: 0.6056\n",
      "63 Training acc: 0.6144 Validation acc: 0.602\n",
      "64 Training acc: 0.6032 Validation acc: 0.591\n",
      "65 Training acc: 0.602236 Validation acc: 0.586\n",
      "66 Training acc: 0.602455 Validation acc: 0.5904\n",
      "67 Training acc: 0.616727 Validation acc: 0.6056\n",
      "68 Training acc: 0.616509 Validation acc: 0.6034\n",
      "69 Training acc: 0.617 Validation acc: 0.602\n",
      "70 Training acc: 0.615018 Validation acc: 0.6028\n",
      "71 Training acc: 0.617909 Validation acc: 0.6038\n",
      "72 Training acc: 0.609564 Validation acc: 0.5988\n",
      "73 Training acc: 0.588473 Validation acc: 0.5794\n",
      "74 Training acc: 0.6162 Validation acc: 0.5924\n",
      "75 Training acc: 0.611818 Validation acc: 0.6006\n",
      "76 Training acc: 0.605036 Validation acc: 0.605\n",
      "77 Training acc: 0.608309 Validation acc: 0.6048\n",
      "78 Training acc: 0.608945 Validation acc: 0.6086\n",
      "79 Training acc: 0.615855 Validation acc: 0.6034\n",
      "80 Training acc: 0.606345 Validation acc: 0.604\n",
      "81 Training acc: 0.602582 Validation acc: 0.6004\n",
      "82 Training acc: 0.610764 Validation acc: 0.5984\n",
      "83 Training acc: 0.614727 Validation acc: 0.602\n",
      "84 Training acc: 0.596636 Validation acc: 0.5866\n",
      "85 Training acc: 0.602273 Validation acc: 0.594\n",
      "86 Training acc: 0.594982 Validation acc: 0.5814\n",
      "87 Training acc: 0.6144 Validation acc: 0.606\n",
      "88 Training acc: 0.597545 Validation acc: 0.5798\n",
      "89 Training acc: 0.608873 Validation acc: 0.6042\n",
      "90 Training acc: 0.601291 Validation acc: 0.5872\n",
      "91 Training acc: 0.608509 Validation acc: 0.594\n",
      "92 Training acc: 0.604855 Validation acc: 0.587\n",
      "93 Training acc: 0.609727 Validation acc: 0.5944\n",
      "94 Training acc: 0.606691 Validation acc: 0.5946\n",
      "95 Training acc: 0.609691 Validation acc: 0.5876\n",
      "96 Training acc: 0.619418 Validation acc: 0.6118\n",
      "97 Training acc: 0.611036 Validation acc: 0.5968\n",
      "98 Training acc: 0.620164 Validation acc: 0.6066\n",
      "99 Training acc: 0.608873 Validation acc: 0.5982\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "#         for iteration in range(mnist.train.num_examples // batch_size):\n",
    "#             X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "#             X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Training acc:\", acc_train, \"Validation acc:\", acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\python3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\python3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\python3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.933333 Test accuracy: 0.9311\n",
      "1 Train accuracy: 0.966667 Test accuracy: 0.9522\n",
      "2 Train accuracy: 0.973333 Test accuracy: 0.9584\n",
      "3 Train accuracy: 0.96 Test accuracy: 0.9613\n",
      "4 Train accuracy: 0.966667 Test accuracy: 0.9659\n",
      "5 Train accuracy: 0.966667 Test accuracy: 0.9694\n",
      "6 Train accuracy: 0.973333 Test accuracy: 0.9692\n",
      "7 Train accuracy: 0.973333 Test accuracy: 0.9741\n",
      "8 Train accuracy: 0.953333 Test accuracy: 0.972\n",
      "9 Train accuracy: 0.98 Test accuracy: 0.973\n",
      "10 Train accuracy: 0.98 Test accuracy: 0.972\n",
      "11 Train accuracy: 0.973333 Test accuracy: 0.9675\n",
      "12 Train accuracy: 0.98 Test accuracy: 0.9707\n",
      "13 Train accuracy: 0.973333 Test accuracy: 0.9732\n",
      "14 Train accuracy: 0.973333 Test accuracy: 0.9734\n",
      "15 Train accuracy: 0.986667 Test accuracy: 0.9729\n",
      "16 Train accuracy: 1.0 Test accuracy: 0.9717\n",
      "17 Train accuracy: 0.986667 Test accuracy: 0.9732\n",
      "18 Train accuracy: 0.98 Test accuracy: 0.9746\n",
      "19 Train accuracy: 0.986667 Test accuracy: 0.9751\n",
      "20 Train accuracy: 0.98 Test accuracy: 0.978\n",
      "21 Train accuracy: 0.98 Test accuracy: 0.9765\n",
      "22 Train accuracy: 0.973333 Test accuracy: 0.9798\n",
      "23 Train accuracy: 0.98 Test accuracy: 0.9693\n",
      "24 Train accuracy: 0.986667 Test accuracy: 0.9761\n",
      "25 Train accuracy: 0.993333 Test accuracy: 0.9722\n",
      "26 Train accuracy: 0.966667 Test accuracy: 0.9767\n",
      "27 Train accuracy: 1.0 Test accuracy: 0.9767\n",
      "28 Train accuracy: 0.98 Test accuracy: 0.9771\n",
      "29 Train accuracy: 1.0 Test accuracy: 0.9769\n",
      "30 Train accuracy: 0.993333 Test accuracy: 0.9778\n",
      "31 Train accuracy: 0.986667 Test accuracy: 0.9783\n",
      "32 Train accuracy: 0.98 Test accuracy: 0.9715\n",
      "33 Train accuracy: 0.993333 Test accuracy: 0.9773\n",
      "34 Train accuracy: 0.986667 Test accuracy: 0.9785\n",
      "35 Train accuracy: 1.0 Test accuracy: 0.9777\n",
      "36 Train accuracy: 1.0 Test accuracy: 0.9792\n",
      "37 Train accuracy: 0.993333 Test accuracy: 0.9774\n",
      "38 Train accuracy: 0.986667 Test accuracy: 0.9785\n",
      "39 Train accuracy: 0.986667 Test accuracy: 0.9769\n",
      "40 Train accuracy: 0.98 Test accuracy: 0.977\n",
      "41 Train accuracy: 0.993333 Test accuracy: 0.9785\n",
      "42 Train accuracy: 0.993333 Test accuracy: 0.9765\n",
      "43 Train accuracy: 0.993333 Test accuracy: 0.9727\n",
      "44 Train accuracy: 0.973333 Test accuracy: 0.9741\n",
      "45 Train accuracy: 0.98 Test accuracy: 0.9793\n",
      "46 Train accuracy: 0.993333 Test accuracy: 0.9803\n",
      "47 Train accuracy: 0.993333 Test accuracy: 0.9749\n",
      "48 Train accuracy: 0.993333 Test accuracy: 0.9793\n",
      "49 Train accuracy: 1.0 Test accuracy: 0.9778\n",
      "50 Train accuracy: 0.993333 Test accuracy: 0.9769\n",
      "51 Train accuracy: 0.986667 Test accuracy: 0.9724\n",
      "52 Train accuracy: 0.986667 Test accuracy: 0.9714\n",
      "53 Train accuracy: 0.993333 Test accuracy: 0.9796\n",
      "54 Train accuracy: 0.986667 Test accuracy: 0.9759\n",
      "55 Train accuracy: 1.0 Test accuracy: 0.9788\n",
      "56 Train accuracy: 0.993333 Test accuracy: 0.9787\n",
      "57 Train accuracy: 0.993333 Test accuracy: 0.9771\n",
      "58 Train accuracy: 0.973333 Test accuracy: 0.9685\n",
      "59 Train accuracy: 0.993333 Test accuracy: 0.9804\n",
      "60 Train accuracy: 1.0 Test accuracy: 0.98\n",
      "61 Train accuracy: 1.0 Test accuracy: 0.9794\n",
      "62 Train accuracy: 0.993333 Test accuracy: 0.9791\n",
      "63 Train accuracy: 0.986667 Test accuracy: 0.9796\n",
      "64 Train accuracy: 0.993333 Test accuracy: 0.9777\n",
      "65 Train accuracy: 1.0 Test accuracy: 0.9803\n",
      "66 Train accuracy: 1.0 Test accuracy: 0.9813\n",
      "67 Train accuracy: 0.986667 Test accuracy: 0.9787\n",
      "68 Train accuracy: 1.0 Test accuracy: 0.9794\n",
      "69 Train accuracy: 0.993333 Test accuracy: 0.9798\n",
      "70 Train accuracy: 0.986667 Test accuracy: 0.9811\n",
      "71 Train accuracy: 1.0 Test accuracy: 0.975\n",
      "72 Train accuracy: 1.0 Test accuracy: 0.9763\n",
      "73 Train accuracy: 1.0 Test accuracy: 0.98\n",
      "74 Train accuracy: 0.993333 Test accuracy: 0.9762\n",
      "75 Train accuracy: 0.993333 Test accuracy: 0.9768\n",
      "76 Train accuracy: 0.986667 Test accuracy: 0.9755\n",
      "77 Train accuracy: 1.0 Test accuracy: 0.9786\n",
      "78 Train accuracy: 0.993333 Test accuracy: 0.9771\n",
      "79 Train accuracy: 0.993333 Test accuracy: 0.9746\n",
      "80 Train accuracy: 0.98 Test accuracy: 0.9778\n",
      "81 Train accuracy: 1.0 Test accuracy: 0.9756\n",
      "82 Train accuracy: 0.993333 Test accuracy: 0.9777\n",
      "83 Train accuracy: 0.993333 Test accuracy: 0.9799\n",
      "84 Train accuracy: 1.0 Test accuracy: 0.9789\n",
      "85 Train accuracy: 1.0 Test accuracy: 0.9767\n",
      "86 Train accuracy: 1.0 Test accuracy: 0.977\n",
      "87 Train accuracy: 0.986667 Test accuracy: 0.9756\n",
      "88 Train accuracy: 0.993333 Test accuracy: 0.9781\n",
      "89 Train accuracy: 0.986667 Test accuracy: 0.9786\n",
      "90 Train accuracy: 1.0 Test accuracy: 0.9769\n",
      "91 Train accuracy: 1.0 Test accuracy: 0.9782\n",
      "92 Train accuracy: 0.993333 Test accuracy: 0.9775\n",
      "93 Train accuracy: 1.0 Test accuracy: 0.975\n",
      "94 Train accuracy: 1.0 Test accuracy: 0.9787\n",
      "95 Train accuracy: 0.973333 Test accuracy: 0.9756\n",
      "96 Train accuracy: 0.993333 Test accuracy: 0.9806\n",
      "97 Train accuracy: 1.0 Test accuracy: 0.9789\n",
      "98 Train accuracy: 0.98 Test accuracy: 0.967\n",
      "99 Train accuracy: 1.0 Test accuracy: 0.9784\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 时间序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min, t_max = 0, 30\n",
    "resolution = 0.1\n",
    "\n",
    "def time_series(t):\n",
    "    return t * np.sin(t) / 3 + 2 * np.sin(t*5)\n",
    "\n",
    "def next_batch(batch_size, n_steps):\n",
    "    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)\n",
    "    Ts = t0 + np.arange(0., n_steps + 1) * resolution\n",
    "    ys = time_series(Ts)\n",
    "    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_steps, n_inputs))\n",
    "y = tf.placeholder(tf.float32, shape=(None, n_steps, n_outputs))\n",
    "\n",
    "#cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)\n",
    "cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "    tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu), output_size=n_outputs)\n",
    "\n",
    "outputs, ststes = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 11.9672575\n",
      "100 \tMSE: 0.52584445\n",
      "200 \tMSE: 0.14959829\n",
      "300 \tMSE: 0.07381975\n",
      "400 \tMSE: 0.06171744\n",
      "500 \tMSE: 0.05968452\n",
      "600 \tMSE: 0.055536177\n",
      "700 \tMSE: 0.047983035\n",
      "800 \tMSE: 0.050073363\n",
      "900 \tMSE: 0.04728166\n",
      "1000 \tMSE: 0.047391903\n",
      "1100 \tMSE: 0.048076287\n",
      "1200 \tMSE: 0.040791243\n",
      "1300 \tMSE: 0.0479767\n",
      "1400 \tMSE: 0.04211445\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 1500\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(iteration, \"\\tMSE:\", mse)\n",
    "            \n",
    "    saver.save(sess, \"./model/rnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "resolution = 0.1\n",
    "t_instance = np.linspace(12.2, 12.2 + resolution * (n_steps + 1), n_steps + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/rnn\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./model/rnn\")\n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-3.406515 ]\n",
      "  [-2.4501145]\n",
      "  [-1.1305888]\n",
      "  [ 0.7817146]\n",
      "  [ 2.2008858]\n",
      "  [ 3.138787 ]\n",
      "  [ 3.399897 ]\n",
      "  [ 3.3627138]\n",
      "  [ 2.8842826]\n",
      "  [ 2.2652197]\n",
      "  [ 1.650614 ]\n",
      "  [ 1.5299088]\n",
      "  [ 1.8965788]\n",
      "  [ 2.731001 ]\n",
      "  [ 3.9058359]\n",
      "  [ 5.14548  ]\n",
      "  [ 6.144004 ]\n",
      "  [ 6.6781516]\n",
      "  [ 6.6523943]\n",
      "  [ 6.0744486]]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_steps, n_inputs))\n",
    "y = tf.placeholder(tf.float32, shape=(None, n_steps, n_outputs))\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "rnn_outputs, ststes = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, shape=(-1, n_neurons))\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, shape=(-1, n_steps, n_outputs))\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1500\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(iteration, \"\\tMSE:\", mse)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
