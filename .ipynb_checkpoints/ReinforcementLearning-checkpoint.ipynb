{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pyglet.gl import gl_info\n",
    "    openai_cart_pole_rendering = True   # no problem, let's use OpenAI gym's rendering function\n",
    "except Exception:\n",
    "    openai_cart_pole_rendering = False  # probably no X server available, let's use our own rendering function\n",
    "\n",
    "def render_cart_pole(env, obs):\n",
    "    if openai_cart_pole_rendering:\n",
    "        # use OpenAI gym's rendering function\n",
    "        return env.render(mode=\"rgb_array\")\n",
    "    else:\n",
    "        # rendering for the cart pole environment (in case OpenAI gym can't do it)\n",
    "        img_w = 600\n",
    "        img_h = 400\n",
    "        cart_w = img_w // 12\n",
    "        cart_h = img_h // 15\n",
    "        pole_len = img_h // 3.5\n",
    "        pole_w = img_w // 80 + 1\n",
    "        x_width = 2\n",
    "        max_ang = 0.2\n",
    "        bg_col = (255, 255, 255)\n",
    "        cart_col = 0x000000 # Blue Green Red\n",
    "        pole_col = 0x669acc # Blue Green Red\n",
    "\n",
    "        pos, vel, ang, ang_vel = obs\n",
    "        img = Image.new('RGB', (img_w, img_h), bg_col)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        cart_x = pos * img_w // x_width + img_w // x_width\n",
    "        cart_y = img_h * 95 // 100\n",
    "        top_pole_x = cart_x + pole_len * np.sin(ang)\n",
    "        top_pole_y = cart_y - cart_h // 2 - pole_len * np.cos(ang)\n",
    "        draw.line((0, cart_y, img_w, cart_y), fill=0)\n",
    "        draw.rectangle((cart_x - cart_w // 2, cart_y - cart_h // 2, cart_x + cart_w // 2, cart_y + cart_h // 2), fill=cart_col) # draw cart\n",
    "        draw.line((cart_x, cart_y - cart_h // 2, top_pole_x, top_pole_y), fill=pole_col, width=pole_w) # draw pole\n",
    "        return np.array(img)\n",
    "\n",
    "def plot_cart_pole(env, obs):\n",
    "    plt.close()  # or else nbagg sometimes plots in the previous cell\n",
    "    img = render_cart_pole(env, obs)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01206774,  0.03276225, -0.00039932, -0.03195472])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABAVJREFUeJzt3NFJw2AYQNH8kiWcwzWco85k53AN53CM+FJErA9CW/94PQcCbSHwPbSXj5B0bNu2ANBzN3sAAG5D4AGiBB4gSuABogQeIErgAaIEHiBK4AGiBB4gap09wInHaQHOjUtOtsEDRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlMADRAk8QJTAA0StsweA2V6PT2efPRyeJ0wC12WDB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBJ2mM8ePjFufDHgg8QNQ6ewDYg5e3w8frx/vjxEngemzw/Huf4/7de/irBB4gSuABogSef+/rNXfX4KkY27bNnmFZlmUXQ9Dxm7cv7uQ3RNNFX2QbPECUwANECTxAlMADRAk8QJTAA0QJPECUwANECTxAlL8LJsnTpWCDB8gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIWmcPcDJmDwBQY4MHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIEniAKIEHiBJ4gCiBB4gSeIAogQeIegekvxw7q/XkIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# img = env.render(mode=\"rgb_array\")\n",
    "# img\n",
    "plot_cart_pole(env, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 1\n",
    "obs, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01141249,  0.22788993, -0.00103841, -0.3247636 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs #obs[0] 小推车水平位置 obs[1] 速度 obs[2] 杆的角度  obs[3] 角速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_policy(obs):\n",
    "    angle = obs[2]\n",
    "    return 0 if angle < 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = [1, 2, 1, 0]\n",
    "basic_policy(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = []\n",
    "for episode in range(500):\n",
    "    episode_rewards = 0\n",
    "    obs = env.reset()\n",
    "    for step in range(1000):\n",
    "        action = basic_policy(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_rewards += reward\n",
    "        if done:\n",
    "            break\n",
    "    totals.append(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42.23, 9.029346598730164, 24.0, 72.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(totals), np.std(totals), np.min(totals), np.max(totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 4\n",
    "n_hidden = 4\n",
    "n_outputs = 1\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "initializer = tf.variance_scaling_initializer()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
    "\n",
    "hidden = tf.layers.dense(X, n_hidden, activation=tf.nn.elu,\n",
    "                         kernel_initializer=initializer)\n",
    "logits = tf.layers.dense(hidden, n_outputs)\n",
    "outputs = tf.nn.sigmoid(logits)\n",
    "\n",
    "p_left_and_right = tf.concat(axis=1, values=[outputs, 1 - outputs])\n",
    "\"\"\"\n",
    "从multinomial分布 中采样，样本个数是num_samples，每个样本被采样的概率由logits给出\n",
    "tf.multinomial(logits, \n",
    "               num_samples, \n",
    "               seed=None, \n",
    "               name=None)\n",
    "\"\"\"\n",
    "action = tf.multinomial(tf.log(p_left_and_right), num_samples=1)\n",
    "\n",
    "y = 1 - tf.to_float(action)\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(cross_entropy)\n",
    "gradients = [grad for grad, variable in grads_and_vars]\n",
    "gradient_placeholders = []\n",
    "grads_and_vars_feed = []\n",
    "for grad, variable in grads_and_vars:\n",
    "    gradient_placeholder = tf.placeholder(tf.float32, grad.get_shape())\n",
    "    gradient_placeholders.append(gradient_placeholder)\n",
    "    grads_and_vars_feed.append((gradient_placeholder, variable))\n",
    "\n",
    "training_op = optimizer.apply_gradients(grads_and_vars=grads_and_vars_feed)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Placeholder_1:0' shape=(4, 4) dtype=float32>,\n",
       " <tf.Tensor 'Placeholder_2:0' shape=(4,) dtype=float32>,\n",
       " <tf.Tensor 'Placeholder_3:0' shape=(4, 1) dtype=float32>,\n",
       " <tf.Tensor 'Placeholder_4:0' shape=(1,) dtype=float32>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor 'Placeholder_1:0' shape=(4, 4) dtype=float32>,\n",
       "  <tf.Variable 'dense/kernel:0' shape=(4, 4) dtype=float32_ref>),\n",
       " (<tf.Tensor 'Placeholder_2:0' shape=(4,) dtype=float32>,\n",
       "  <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32_ref>),\n",
       " (<tf.Tensor 'Placeholder_3:0' shape=(4, 1) dtype=float32>,\n",
       "  <tf.Variable 'dense_1/kernel:0' shape=(4, 1) dtype=float32_ref>),\n",
       " (<tf.Tensor 'Placeholder_4:0' shape=(1,) dtype=float32>,\n",
       "  <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32_ref>)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_and_vars_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_rate):\n",
    "    discounted_rewards = np.zeros(len(rewards))\n",
    "    cumulative_rewards = 0\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        cumulative_rewards = rewards[step] + cumulative_rewards * discount_rate\n",
    "        discounted_rewards[step] = cumulative_rewards\n",
    "    return discounted_rewards\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_rate):\n",
    "    all_discounted_rewards = [discount_rewards(rewards, discount_rate) for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean) / reward_std for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-22., -40., -50.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_rewards([10, 0, -50], discount_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.28435071, -0.86597718, -1.18910299]),\n",
       " array([1.26665318, 1.0727777 ])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_and_normalize_rewards([[10, 0, -50], [10, 20]], discount_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 249"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "n_games_per_update = 10\n",
    "n_max_steps = 1000\n",
    "n_iterations = 250\n",
    "save_iterations = 10\n",
    "discount_rate = 0.95\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        print(\"\\rIteration: {}\".format(iteration), end=\"\")\n",
    "        all_rewards = []\n",
    "        all_gradients = []\n",
    "        for game in range(n_games_per_update):\n",
    "            current_rewards = []\n",
    "            current_gradients = []\n",
    "            obs = env.reset()\n",
    "            for step in range(n_max_steps):\n",
    "                action_val, gradients_val = sess.run([action, gradients],\n",
    "                                                     feed_dict={X: obs.reshape(1, n_inputs)})\n",
    "                obs, reward, done, info = env.step(action_val[0][0])\n",
    "                current_rewards.append(reward)\n",
    "                current_gradients.append(gradients_val)\n",
    "                if done:\n",
    "                    break\n",
    "            all_rewards.append(current_rewards)\n",
    "            all_gradients.append(current_gradients)\n",
    "        \n",
    "        all_rewards = discount_and_normalize_rewards(all_rewards, discount_rate)\n",
    "        feed_dict = {}\n",
    "        for var_index, gradient_placeholder in enumerate(gradient_placeholders):\n",
    "            mean_gradients = np.mean([reward * all_gradients[game_index][step][var_index]\n",
    "                                      for game_index, rewards in enumerate(all_rewards)\n",
    "                                          for step, reward in enumerate(rewards)], axis=0)\n",
    "            feed_dict[gradient_placeholder] = mean_gradients\n",
    "        sess.run(training_op, feed_dict=feed_dict)\n",
    "        if iteration % save_iterations == 0:\n",
    "            saver.save(sess, \"./model/policy_gradients.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/policy_gradients.ckpt\n"
     ]
    }
   ],
   "source": [
    "n_max_steps = 1000\n",
    "frames = []\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "obs = env.reset()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./model/policy_gradients.ckpt\")\n",
    "    for step in range(n_max_steps):\n",
    "        img = render_cart_pole(env, obs)\n",
    "        frames.append(img)\n",
    "        action_val = action.eval(feed_dict={X: obs.reshape(1, n_inputs)})\n",
    "        obs, reward, done, info = env.step(action_val[0][0])\n",
    "        if done:\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 马尔可夫决策过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "T = np.array([ # T(s, a, sp)是假设代理选择行为a, 从状态s到状态sp的转移概率\n",
    "                            [[0.7, 0.3, 0.0],   [1.0, 0.0, 0.0], [0.8, 0.2, 0.0]],\n",
    "#s0状态下选择行为a0的转移概率    s0   s1   s2  a1:  s0   s1   s2 a2: s0   s1   s2 \n",
    "    [[0.0, 1.0, 0.0], [nan, nan, nan], [0.0, 0.0, 1.0]],\n",
    "    [[nan, nan, nan], [0.8, 0.1, 0.1], [nan, nan, nan]],\n",
    "])\n",
    "R = np.array([ # R(s, a, sp)是假设代理选择行为a, 从状态s到状态sp获得的回报\n",
    "    [[10., 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
    "    [[10., 0.0, 0.0], [nan, nan, nan], [0.0, 0.0, -50.]],\n",
    "    [[nan, nan, nan], [40., 0.0, 0.0], [nan, nan, nan]],\n",
    "])\n",
    "possible_actions = [[0, 1, 2], [0, 2], [1]]  #每个状态下可能选择的行为 0: a0  1: a1  2: a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q值迭代算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.full((3, 3), -np.inf)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0, 1, 2]\n",
      "1 [0, 2]\n",
      "2 [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.],\n",
       "       [  0., -inf,   0.],\n",
       "       [-inf,   0., -inf]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for state, actions in enumerate(possible_actions):\n",
    "    print(state, actions)\n",
    "    Q[state, actions] = 0.0\n",
    "Q #最优Q值是Q(s, a)是代理到达状态s并选择了行为a后，假设在此行为后行为最优，预期的平均折扣后未来回报的总和\n",
    "# 状态s2不能选择行为a1: inf  状态s3不能选择行为a0 a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.89925005, 20.80428755, 16.86759588],\n",
       "       [ 1.12082922,        -inf,  1.17982024],\n",
       "       [       -inf, 53.87349498,        -inf]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "discount_rate = 0.95\n",
    "n_iterations = 1000\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    Q_prev = Q.copy()\n",
    "    for s in range(3):\n",
    "        for a in possible_actions[s]:\n",
    "            Q[s, a] = np.sum([\n",
    "                T[s, a, sp] * (R[s, a, sp] + discount_rate * np.max(Q_prev[sp]))\n",
    "                for sp in range(3)\n",
    "            ])\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.],\n",
       "       [  0., -inf,   0.],\n",
       "       [-inf,   0., -inf]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy.random as rnd\n",
    "\n",
    "learning_rate0 = 0.05\n",
    "learning_rate_decay = 0.1\n",
    "discount_rate = 0.95\n",
    "n_iterations = 20000\n",
    "\n",
    "R = np.array([ # R(s, a, sp)是假设代理选择行为a, 从状态s到状态sp获得的回报\n",
    "    [[10., 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
    "    [[10., 0.0, 0.0], [nan, nan, nan], [0.0, 0.0, -50.]],\n",
    "    [[nan, nan, nan], [40., 0.0, 0.0], [nan, nan, nan]],\n",
    "])\n",
    "\n",
    "Q = np.full((3, 3), -np.inf)\n",
    "possible_actions = [[0, 1, 2], [0, 2], [1]]  #每个状态下可能选择的行为 0: a0  1: a1  2: a2\n",
    "for state, actions in enumerate(possible_actions):\n",
    "    Q[state, actions] = 0.0\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[129.22709332, 121.58217041,  95.07921838],\n",
       "       [ 95.07852648,         -inf, 100.08265945],\n",
       "       [        -inf, 155.50312384,         -inf]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    a = rnd.choice(possible_actions[s])\n",
    "    sp = rnd.choice(range(3), p=T[s, a])\n",
    "    reward = R[s, a, sp]\n",
    "    learning_rate = learning_rate0 / (1 + iteration * learning_rate_decay)\n",
    "    Q[s, a] = learning_rate * Q[s, a] + (1 - learning_rate) * (reward + discount_rate * np.max(Q[sp]))\n",
    "    s = sp\n",
    "    \n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用DQN学习玩吃豆人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"MsPacman-v0\")\n",
    "obs = env.reset()\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mspacman_color = 210 + 164 + 74\n",
    "\n",
    "def preprocess_observation(obs):\n",
    "    img = obs[1:176:2, ::2]\n",
    "    img = img.sum(axis=2)\n",
    "    img[img == mspacman_color] = 0\n",
    "    img = (img // 3 - 128).astype(np.int8)\n",
    "    return img.reshape(88, 80, 1)\n",
    "\n",
    "img = preprocess_observation(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 80, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(11, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original observation (160×210 RGB)\")\n",
    "plt.imshow(obs)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Preprocessed observation (88×80 greyscale)\")\n",
    "plt.imshow(img.reshape(88, 80), interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_height = 88\n",
    "input_width = 80\n",
    "input_channels = 1\n",
    "conv_n_maps = [32, 64, 64]\n",
    "conv_kernel_size = [(8, 8), (4, 4), (3, 3)]\n",
    "conv_strides = [4, 2, 1]\n",
    "conv_padding = [\"SAME\"] * 3\n",
    "conv_activation = [tf.nn.relu] * 3\n",
    "n_hidden_in = 64 * 11 * 10\n",
    "n_hidden = 512\n",
    "hidden_activation = tf.nn.relu\n",
    "n_outputs = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
